#+TITLE:     Correlation and Causation
#+OPTIONS:   H:2
#+LaTeX_HEADER: \newcommand \E {\mathop{\mbox{\ensuremath{\mathbb{E}}}}\nolimits}
#+LaTeX_HEADER: \newcommand\ind[1]{\mathop{\mbox{\ensuremath{\mathbb{I}}}}\left\{#1\right\}}
#+LaTeX_HEADER: \renewcommand \Pr {\mathop{\mbox{\ensuremath{\mathbb{P}}}}\nolimits}
#+LaTeX_HEADER: \newcommand \defn {\mathrel{\triangleq}}
#+LaTeX_HEADER: \newcommand \Reals {\mathbb{R}}
#+LaTeX_HEADER: \newcommand \Param {\Theta}
#+LaTeX_HEADER: \newcommand \param {\theta}

* Joint and Conditional Probabilities
** Setting
#+ATTR_BEAMER: :overlay <+->
*** Outline
#+ATTR_BEAMER: :overlay <+->
- Random variables $x, y$ taking values in $\mathcal{X}, {Y}$.
- We write $\Pr(x,y)$ to informally mean their joint distribution.

*** Formal definition
#+ATTR_BEAMER: :overlay <+->
- Underlying probability space $P, \Omega, \Sigma$ with
- Outcome space $\Omega$
- Event space $\Sigma$, so that $A \in \Sigma$ are subsets of $\Omega$.
- Probability measure $P : \Sigma \to \Omega$.
- RVs $x : \Omega \to \mathcal{X}$, $y : \Omega \to \mathcal{Y}$
- Joint measure $P_{x,y}(S_x, S_y) \defn P(\{\omega : x(\omega) \in S_x, y(\omega) \in S_y\})$

** Conditional probabilities
#+ATTR_BEAMER: :overlay <+->
**** Definition
The conditional distribution of $x$ given $y$ is:
\[
\Pr(x | y) = \Pr(x, y) / \Pr(y)
\]
Thus, for every value of $y$ we get a different distribution for $x$.

**** Recall definition for events
This has the same form.
\[
P(A | B) = P(A \cap B) / P(B).
\]

** Discrete $x, y$

*** Bernoulli-distributed $x, y \in \{0,1\}$
- $\Pr(x = 1) = \theta$
- $\Pr(y = 1 | x = 0) = v_0$
- $\Pr(y = 1 | x = 1) = v_1$
- $\Pr(x = 1) = ?$

*** Python example
#+BEGIN_SRC python
import numpy as np
n = 10000
theta = 0.8
v[0] = 0.2
v[1]= 0.8
x = np.random.choice(2, p = [1 - theta, theta], size = n)
y = np.random.choice(2, 
#+END_SRC

* Correlation and independence
** Correlation versus dependence
#+ATTR_BEAMER: :overlay <+->
*** Dependent random variables
#+ATTR_BEAMER: :overlay <+->
- $x, y$ are independent if $\Pr(x,y) = \Pr(x)\Pr(y)$
- equivalently, if $\Pr(x | y) = \Pr(x)$
- $x, y$ are dependent if they are not independent.

*** Correlated random variables
#+ATTR_BEAMER: :overlay <+->
- $x, y$ are uncorrelated if $\E(x,y) = \E(x)\E(y)$
- Equivalently, if $\E(x | y) = \E(x)$
- $x, y$ are correlated if $\E(x,y) \neq \E(x)\E(y)$

*** Theorem
- If $x, y$ are correlated then they are dependent.
- If $x, y$ are independent the they are uncorrelated.



